{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Install Required Libraries"
      ],
      "metadata": {
        "id": "TNRx_J4Jwcik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap imbalanced-learn joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9TmLL69w3C1",
        "outputId": "0448b82b-199e-4b31-f00b-6ac718e9b00a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Import Libraries"
      ],
      "metadata": {
        "id": "lvJ92ZInw44S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap  # For explainability\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib"
      ],
      "metadata": {
        "id": "Z3dHllJFxmkX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Load Dataset"
      ],
      "metadata": {
        "id": "8MX8dxYuxqwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/CESAW_Task_fact.csv\")\n",
        "\n",
        "# Display dataset overview\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S38ueqs5x2op",
        "outputId": "0a28590e-97eb-4894-997c-e5dd3db7dd51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "    task_id            task_type  task_complexity  task_priority  \\\n",
            "0  7bed2185           Bug Fixing                2              3   \n",
            "1  87d513d7           Bug Fixing                1              2   \n",
            "2  c8a32d63          Code Review                1              2   \n",
            "3  a9db64e2  Feature Development                2              3   \n",
            "4  9e34afcf  Feature Development                2              3   \n",
            "\n",
            "   estimated_effort_hours team_id  team_experience_level  total_members  \\\n",
            "0                    7.23     T18                      1             18   \n",
            "1                   13.20      T7                      2              6   \n",
            "2                   47.28     T44                      1             15   \n",
            "3                    7.39      T6                      3             13   \n",
            "4                   28.26     T25                      2             19   \n",
            "\n",
            "   past_projects_completed          specialization  team_skillset_match  \\\n",
            "0                       22  Mobile App Development                78.37   \n",
            "1                       17                 AI & ML                85.38   \n",
            "2                       29  Mobile App Development                64.65   \n",
            "3                       53  Mobile App Development                55.81   \n",
            "4                       26           Cybersecurity                95.28   \n",
            "\n",
            "   team_availability assigned_team  \n",
            "0              58.51           T18  \n",
            "1              76.15            T7  \n",
            "2              98.26           T44  \n",
            "3              50.85            T6  \n",
            "4              67.65           T25  \n",
            "\n",
            "Missing Values Summary:\n",
            "task_id                    0\n",
            "task_type                  0\n",
            "task_complexity            0\n",
            "task_priority              0\n",
            "estimated_effort_hours     0\n",
            "team_id                    0\n",
            "team_experience_level      0\n",
            "total_members              0\n",
            "past_projects_completed    0\n",
            "specialization             0\n",
            "team_skillset_match        0\n",
            "team_availability          0\n",
            "assigned_team              0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Encode Categorical Variables\n",
        "\n",
        "Since the dataset has categorical features, they need to be converted into numerical values before training."
      ],
      "metadata": {
        "id": "4T4I-rCFx8-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store label encoders\n",
        "label_encoders = {}\n",
        "\n",
        "# Define categorical columns that need encoding\n",
        "categorical_columns = ['task_type', 'specialization', 'assigned_team', 'team_id']\n",
        "\n",
        "# Encode each categorical column\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Store encoders for later use\n",
        "\n",
        "print(\"\\nCategorical Variables Encoded Successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8UbjhRNyC-K",
        "outputId": "96f390f5-d202-4dc6-9302-b7bedcf1a285"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Categorical Variables Encoded Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Select Features and Target Variable\n",
        "\n",
        "The dataset is split into independent features (X) and the target variable (y)."
      ],
      "metadata": {
        "id": "TV6o_oPfyM7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target variable (y)\n",
        "X = df.drop(columns=['task_id', 'assigned_team'])\n",
        "y = df['assigned_team']\n",
        "\n",
        "print(f\"\\nFeature Selection Completed: {X.shape[1]} features selected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TYwr7jNyRU6",
        "outputId": "9aca6f3c-2987-4fb0-f407-e1067a82e072"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Selection Completed: 11 features selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Standardize Numerical Features\n",
        "\n",
        "To ensure consistent scaling across features, we apply standardization."
      ],
      "metadata": {
        "id": "h3kAsnH5yVf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply scaling\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\nFeature Scaling Completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh8jouKSyZYp",
        "outputId": "1ba90b3a-6bfc-4f0f-d88a-d2905be440e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Scaling Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Split Dataset into Training & Testing Sets\n",
        "\n",
        "I divide the dataset into 80% training and 20% testing to validate model performance."
      ],
      "metadata": {
        "id": "BHwPqgPiyfza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nData Split: {X_train.shape[0]} training rows, {X_test.shape[0]} testing rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLF3Fq-ByqbC",
        "outputId": "e2f39170-91aa-4f21-ce03-9031f21d95a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Split: 800 training rows, 200 testing rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Handle Class Imbalance Using SMOTE.\n",
        "\n",
        "SMOTE (Synthetic Minority Over-sampling Technique) balances the dataset so that no team is underrepresented."
      ],
      "metadata": {
        "id": "w69-z-wzyvTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nClass Imbalance Handled with SMOTE.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvll9OgAy0g2",
        "outputId": "f3bdfd61-c411-4367-9e37-97b037c89acd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Imbalance Handled with SMOTE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Train an Initial XGBoost Model to Get Feature Importance.\n",
        "\n",
        "XGBoost is trained first to identify the most important features."
      ],
      "metadata": {
        "id": "UAbHcn9Ay61Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an initial XGBoost model\n",
        "xgb_temp = XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
        "xgb_temp.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Identify the top 10 most important features\n",
        "feature_importance = xgb_temp.feature_importances_\n",
        "important_features = np.argsort(feature_importance)[-10:]  # Select indices of top 10 features\n",
        "\n",
        "print(\"\\nTop 10 Important Features Selected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9JkZFN5zBoj",
        "outputId": "2f2f7a52-357e-4ba5-c55d-a96a7185bd74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Important Features Selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Train the Final Models Using Selected Features.\n",
        "\n",
        "Now, I train both XGBoost and RandomForest models using only the most important features."
      ],
      "metadata": {
        "id": "jbQjXpSyzHbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dataset to top 10 selected features\n",
        "X_train_selected = X_train_resampled[:, important_features]\n",
        "X_test_selected = X_test[:, important_features]\n",
        "\n",
        "# Train XGBoost on selected features\n",
        "xgb = XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
        "xgb.fit(X_train_selected, y_train_resampled)\n",
        "\n",
        "# Train Random Forest on the same features\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=30, min_samples_split=5, min_samples_leaf=2, class_weight='balanced', random_state=42)\n",
        "rf.fit(X_train_selected, y_train_resampled)\n",
        "\n",
        "print(\"\\nFinal Models Trained on Selected Features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQX4_01ZzWNB",
        "outputId": "b9e26d7e-78a1-4751-812e-3a6276ad38d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Models Trained on Selected Features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Train SHAP Explainer for Model Interpretability\n",
        "\n",
        "SHAP (SHapley Additive Explanations) helps understand which features influence predictions."
      ],
      "metadata": {
        "id": "KTKaxWzyzdxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SHAP explainer on the trained XGBoost model\n",
        "explainer = shap.Explainer(xgb, X_train_selected)\n",
        "\n",
        "print(\"\\nSHAP Explainer Trained for Model Interpretability.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlme-Iy8zmvu",
        "outputId": "ae2e9ddf-d402-4359-e2b8-5bd00d5810e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SHAP Explainer Trained for Model Interpretability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Make Predictions Using Both Models.\n",
        "\n",
        "I use both models to predict task allocation and apply a majority voting approach."
      ],
      "metadata": {
        "id": "NQU4JBZ3zr3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using XGBoost\n",
        "xgb_preds = xgb.predict(X_test_selected)\n",
        "\n",
        "# Predict using Random Forest\n",
        "rf_preds = rf.predict(X_test_selected)\n",
        "\n",
        "# Apply majority voting (rounding ensures valid team assignments)\n",
        "final_preds = (xgb_preds + rf_preds) // 2\n",
        "\n",
        "print(\"\\nEnsemble Predictions Completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E3i0AxJ0D5c",
        "outputId": "e372e9a9-fe7f-47b4-88fa-d29f41da0143"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble Predictions Completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 13: Evaluate Model Performance.\n",
        "\n",
        "The model is evaluated using accuracy, confusion matrix, and classification report."
      ],
      "metadata": {
        "id": "2DP7ZQmj0IX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model accuracy\n",
        "accuracy = accuracy_score(y_test, final_preds)\n",
        "\n",
        "# Generate confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_test, final_preds)\n",
        "classification_rep = classification_report(y_test, final_preds, output_dict=True, zero_division=1)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"\\nModel Evaluation Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-a1NwYG0NAI",
        "outputId": "4e041277-670e-49e7-be5b-c817a64e57c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation Results:\n",
            "Accuracy: 0.6300\n",
            "Confusion Matrix:\n",
            " [[2 0 0 ... 0 0 0]\n",
            " [0 5 0 ... 0 0 0]\n",
            " [0 1 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 6 0 0]\n",
            " [0 0 0 ... 1 1 0]\n",
            " [0 0 0 ... 0 0 5]]\n",
            "Classification Report:\n",
            " {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2.0}, '1': {'precision': 0.8333333333333334, 'recall': 1.0, 'f1-score': 0.9090909090909091, 'support': 5.0}, '2': {'precision': 1.0, 'recall': 0.8, 'f1-score': 0.8888888888888888, 'support': 5.0}, '3': {'precision': 1.0, 'recall': 0.8, 'f1-score': 0.8888888888888888, 'support': 5.0}, '4': {'precision': 0.5714285714285714, 'recall': 1.0, 'f1-score': 0.7272727272727273, 'support': 4.0}, '5': {'precision': 0.6666666666666666, 'recall': 0.5, 'f1-score': 0.5714285714285714, 'support': 4.0}, '6': {'precision': 1.0, 'recall': 0.75, 'f1-score': 0.8571428571428571, 'support': 4.0}, '7': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 5.0}, '8': {'precision': 1.0, 'recall': 0.75, 'f1-score': 0.8571428571428571, 'support': 4.0}, '9': {'precision': 0.7142857142857143, 'recall': 1.0, 'f1-score': 0.8333333333333334, 'support': 5.0}, '10': {'precision': 0.5, 'recall': 0.6, 'f1-score': 0.5454545454545454, 'support': 5.0}, '11': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, '12': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1-score': 0.5714285714285714, 'support': 3.0}, '13': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1-score': 0.5714285714285714, 'support': 6.0}, '14': {'precision': 0.5, 'recall': 0.25, 'f1-score': 0.3333333333333333, 'support': 4.0}, '15': {'precision': 0.6, 'recall': 0.75, 'f1-score': 0.6666666666666666, 'support': 4.0}, '16': {'precision': 0.6666666666666666, 'recall': 0.4, 'f1-score': 0.5, 'support': 5.0}, '17': {'precision': 0.5, 'recall': 0.25, 'f1-score': 0.3333333333333333, 'support': 4.0}, '18': {'precision': 0.6666666666666666, 'recall': 0.6666666666666666, 'f1-score': 0.6666666666666666, 'support': 3.0}, '19': {'precision': 0.4444444444444444, 'recall': 1.0, 'f1-score': 0.6153846153846154, 'support': 4.0}, '20': {'precision': 0.5, 'recall': 0.25, 'f1-score': 0.3333333333333333, 'support': 4.0}, '21': {'precision': 0.6, 'recall': 0.75, 'f1-score': 0.6666666666666666, 'support': 4.0}, '22': {'precision': 0.3333333333333333, 'recall': 0.5, 'f1-score': 0.4, 'support': 4.0}, '23': {'precision': 0.6, 'recall': 0.6, 'f1-score': 0.6, 'support': 5.0}, '24': {'precision': 1.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, '25': {'precision': 0.25, 'recall': 0.25, 'f1-score': 0.25, 'support': 4.0}, '26': {'precision': 0.42857142857142855, 'recall': 0.75, 'f1-score': 0.5454545454545454, 'support': 4.0}, '27': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1-score': 0.4, 'support': 3.0}, '28': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1-score': 0.4, 'support': 3.0}, '29': {'precision': 0.4, 'recall': 0.5, 'f1-score': 0.4444444444444444, 'support': 4.0}, '30': {'precision': 0.75, 'recall': 0.6, 'f1-score': 0.6666666666666666, 'support': 5.0}, '31': {'precision': 0.75, 'recall': 1.0, 'f1-score': 0.8571428571428571, 'support': 3.0}, '32': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 4.0}, '33': {'precision': 0.6, 'recall': 0.75, 'f1-score': 0.6666666666666666, 'support': 4.0}, '34': {'precision': 0.5, 'recall': 0.25, 'f1-score': 0.3333333333333333, 'support': 4.0}, '35': {'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1-score': 0.3333333333333333, 'support': 3.0}, '36': {'precision': 0.5714285714285714, 'recall': 0.8, 'f1-score': 0.6666666666666666, 'support': 5.0}, '37': {'precision': 0.16666666666666666, 'recall': 0.25, 'f1-score': 0.2, 'support': 4.0}, '38': {'precision': 0.5, 'recall': 0.4, 'f1-score': 0.4444444444444444, 'support': 5.0}, '39': {'precision': 0.25, 'recall': 0.25, 'f1-score': 0.25, 'support': 4.0}, '40': {'precision': 0.5, 'recall': 0.3333333333333333, 'f1-score': 0.4, 'support': 3.0}, '41': {'precision': 0.5, 'recall': 0.25, 'f1-score': 0.3333333333333333, 'support': 4.0}, '42': {'precision': 1.0, 'recall': 0.6666666666666666, 'f1-score': 0.8, 'support': 3.0}, '43': {'precision': 0.75, 'recall': 1.0, 'f1-score': 0.8571428571428571, 'support': 3.0}, '44': {'precision': 1.0, 'recall': 0.75, 'f1-score': 0.8571428571428571, 'support': 4.0}, '45': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 3.0}, '46': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 4.0}, '47': {'precision': 0.8571428571428571, 'recall': 1.0, 'f1-score': 0.9230769230769231, 'support': 6.0}, '48': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.6666666666666666, 'support': 2.0}, '49': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 5.0}, 'accuracy': 0.63, 'macro avg': {'precision': 0.666079365079365, 'recall': 0.615, 'f1-score': 0.6026480186480186, 'support': 200.0}, 'weighted avg': {'precision': 0.6628293650793651, 'recall': 0.63, 'f1-score': 0.6142150072150071, 'support': 200.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 14: Save the Trained Models and Preprocessing Tools.\n",
        "\n",
        "The trained models and preprocessing tools are saved for later use in the API."
      ],
      "metadata": {
        "id": "KDvobQvC0j_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = X.columns[important_features]  # Store selected feature names\n",
        "\n",
        "joblib.dump(xgb, \"task_allocation_xgb.pkl\")\n",
        "joblib.dump(rf, \"task_allocation_rf.pkl\")\n",
        "joblib.dump(scaler, \"T_scaler.pkl\")  # Scaler for future data processing\n",
        "joblib.dump(label_encoders, \"label_encoders.pkl\")  # Label encoders for categorical features\n",
        "joblib.dump(important_features, \"selected_features.pkl\")  # Save feature selection indices\n",
        "joblib.dump(explainer, \"shap_explainer.pkl\")  # Save SHAP explainer\n",
        "\n",
        "print(\"\\nModels, encoders, and SHAP explainer saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAJubd0V0ykJ",
        "outputId": "cac5601d-a1f4-4b60-e430-2af846707457"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Models, encoders, and SHAP explainer saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 15: Save Model Performance Metrics.\n",
        "\n",
        "The accuracy, confusion matrix, and classification report are stored separately for API integration."
      ],
      "metadata": {
        "id": "SBxXGRfI04rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(accuracy, \"task_allocation_accuracy.pkl\")\n",
        "joblib.dump(conf_matrix, \"task_allocation_conf_matrix.pkl\")\n",
        "joblib.dump(classification_rep, \"task_allocation_classification_report.pkl\")\n",
        "\n",
        "print(\"Task Allocation Model Performance Saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mraCXyF509xd",
        "outputId": "f497e4ee-b081-48f8-e081-174ab6296b6e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task Allocation Model Performance Saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ttynJx9vfLq3"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ]
}